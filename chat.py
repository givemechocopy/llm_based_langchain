import streamlit as st
from langchain.chat_models import ChatOpenAI
from dotenv import load_dotenv
import os

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# API í‚¤ë¥¼ í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê°€ì ¸ì˜´
openai_api_key = os.getenv("OPENAI_API_KEY")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ")
st.title('ğŸ¦œğŸ”— ë­ë“ ì§€ ì§ˆë¬¸í•˜ì„¸ìš”~ ')

def generate_response(input_text):
    # openai_api_key ì§ì ‘ ì „ë‹¬
    llm = ChatOpenAI(
        temperature=0,  # ì°½ì˜ì„± 0ìœ¼ë¡œ ì„¤ì •
        model_name='gpt-4o',  # ëª¨ë¸ëª…
        openai_api_key=openai_api_key
    )
    st.info(llm.predict(input_text))

with st.form('Question'):
    text = st.text_area('ì§ˆë¬¸ ì…ë ¥:', 'What types of text models does OpenAI provide?') #ì²« í˜ì´ì§€ê°€ ì‹¤í–‰ë  ë•Œ ë³´ì—¬ì¤„ ì§ˆë¬¸
    submitted = st.form_submit_button('ë³´ë‚´ê¸°')
    generate_response(text)
    if submitted:
        generate_response(text)

